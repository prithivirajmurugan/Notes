 docker rm -f $(docker ps -aq)
 docker ps
  
 docker run --name website -d -p 8080:80 nginx:latest
 docker ps --format
 
 docker run --name website-copy --volumes-from website -d -p 8081:80 nginx
 
 
 
 Dockerfile --> build our own images
 
 with Dockerfile create image that can be used to run a container 
 
 images should containing all the things that application needs to run from (snapshot,os,software,appcode)
 
 Build a image:
 
 docker build --tag website:latest .
 
 docker exec -it website bash
 
 docker run --name website -p 8080:80 -d website:latest
 
 every step is a layer and is cached
 
 .dockerignore file
 
 Best practices - Dockerfile
 
FROM node:latest
WORKDIR /app
ADD package*.json ./
RUN npm install
ADD . .
ENV PORT 3000
EXPOSE $PORT
CMD ["npm"," "]



docker build --build-arg=HTTP_PROXY=http://127.0.0.1:8080 --build-arg=HTTPS_PROXY=http://127.0.0.1:8080 -t user-service-api:latest .


reduce the file-size

Alpine --> all image will have an alphine tag

docker pull node:alpine


Tags, Versioning and Tagging

node:8-alpine

Tagging override

whenever a new image is created with existing tag, it usually gets overwritten

docker tag tag-from:latest tag-to:version


Docker registries

Private/Public

1. Docker Hub
2. quay.io
3. Amazon ECR

Docker Hub

docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]

docker login to login

docker push website/latest

docker inspect CONTAINER_NAME/ID

docker logs CONTAINER_NAME/ID

docker logs -f CONTAINER_NAME/ID

getting inside the container

docker exec -it CONTAINER_NAME/ID bash


Container orchestration Tool - Kubernetes

Open-source - manage containerized application

high-availability
scalability
disaster recovery


one master node and several worker node each node has kubelet process

worker node has docker container --> actual app
master node --> entrypoint to K8 cluster - api server,keeps track of whats happening in cluster -controller manager, ensure pods placement- Scheduler,etcd-key value storage

Virtual network - where all nodes talk with each other


Node :

 
 Pod
	smallest unit of K8s, abstraction over container,
	usually one application per pod
	each pod gets its own IP address
 Service
	Permanent IP address
	lifecycle of Pod and Service NOT connected
	external and internal service-api
	Ingress --> external service --> readable address format
	service is also an load balancer
 ConfigMap
	external configuration of your application
	secret: used to store secret data --> base64 encoded\
 Volumes
	physical storge for database -- local or remote
	k8's doesn't manage any cluster
 Deployment
	blueprint for my-app nods
	we don't create pods , we create deployments
	abstraction of pods
	DB cannot be replicate via deployment - it has state
	for stateless apps
 Stateful set
	for stateful apps for databases
	read and writes are syncronised
	not easy so often hosted outside of K8s cluster
	
minikube
	creates Virtual Bosx on your laptop
	Node runs in that Virtual Box
	1 Node K8s cluster
	for testing purposes
Kubectl
	interacting with cluster
	command line tool to speak with Master process
	master process --> API service (UI, API, CLI -> KUBECTL)
	
kubectl create deployment NAME --image=image

kubectl get deployment

kubectl get pods
	
kubectl logs [POD_NAME]

kubectl delete pod [POD_NAME]

kubectl apply-f [config-file-name]

kubectl describe pod [POD_NAME]

kubectl exec -it POD_NAME -- bash

Kuber Config file -- kubectl apply -f config-file.yaml



Simple Pod

apiVersion: v1 //pool of objects to be created from, in this case... get default
kind: Pod // type of object to be created
metadata:
  name: Posts // name of Pod to be created
spec:
  containers: // can create as many containers in a pod
  - name: Posts // name of container to be created
    image: someImage/container:0.0.1  // it no version, then it is latest , get image from dockerhub

We dont usually create Pod with Pod Kind config file

We use Deployment to create Pods and maintain Pods , if new version is created, the deployment is create new Pods and delete old Pods

Simple Deployment

apiVersion: apps/v1
kind: Deployment
metadata:
  name: posts-depl
spec:
  replicas: 3 //no of pods needs to be created
  selector:     //selector of pods to manage
    matchLabels:
      app: posts
  template: // how to manage selected pods
    metadata:
      labels:
       app: posts
    spec:
     containers:
       - name:  my-name
         image: someImage/posts:0.0.1  //latest tag for deployment updation
		 
kubectl get deployments
kubectl describe deployment [depl_name]
kubectl apply -f [config_file_name]
kubectl delete deployment [depl_name]


Use always latest file for deployment -- pushing to cluster is needed


re-build image --> push it to docker hub (docker push [DOCKER_ID]/{IMAGE_NAME] --> kubectl rollout restart deployment [depl_name] (old deployment running)


Types of Services

Cluster-IP --> sets up an easy-to-remember URL to access a pod, only exploses pods in the clustor

Node Port --> Makes a pod accessible from outside the cluster, Usually only used for dev purposes

Load Balancer --> Makes a pod accessible from outside the cluster. This is the right way to expose a pod to the outside world

External Name --> Redirects an in-cluster request to a CNAME url...


Service NodePort creation


apiVersion: v1
kind: Service
metadata:
  name: posts-srv
spec:
  type: NodePort
  selector:
    app: posts  #find all the pods with label of app:posts (deployment config posts)
  ports: # is an array entry
   - name: posts #just for logging purposes
     protocol: TCP
     port: 4000  # NodePort service port
     targetPort: 4000 # port on Pod to be mapped application port

gives a random assigned port through which we can actually request to from browser (3xxx)

kubectl get services
kubectl describe service [SERVICE_NAME]

Service ClusterIP service (for connection between different pods)

apiVersion: v1
kind: Service
metadata:
  name: event-bus-srv
spec:
  selector:
    app: event-bus
  type: ClusterIP    # optional to include
  ports:
  - name: event-bus  # pod in event-bus deployment config
    protocol: TCP
    port: 4005
    targetPort: 4005

Wiring it all up

await axios.post(http://event-bus-srv:4005/events,{data});


LoadBalancer

React app Dev server  is also is in Pod, it only serves the needed HTML,CSS and JS file but the remaining AJAX requests are done by browser only

Request goes to load balancer and response comes out of load balancer , load balancer communicates with cluster IP

LoadBalancer --> gets traffic in to a single pod

ingress or Ingress controller --> A pod with set of routing rules to distribute traffic to other services


ingress-nginx

install using mandatory.yaml 

kubectl apply -f mandatory.yaml(search google)

For ingress configuration

apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: ingress-srv
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: posts.com
      http:
        paths:
          - path: /posts
            backend:
              serviceName: posts-clusterip-srv
              servicePort: 4000



apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 1 
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1:16
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80


referencing values from secret file

env:
        - name: MONGO_INIDB_ROOT_USERNAME
          valueFrom:
            secretKeyRef:
              name: mongodb-secret
              key : mongo-root-username
        - name: MONGO_INITDB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongodb-secret
              key : mongo-root-password
			  
			  
configmap
secret
internal-service (type:ClusterIP)
deployment
external-service --> type:LoadBalancer,nodePort:30001


kubectl sclae deployment POD_NAME --replicas 3

kubectl expose deployment node-app --type NodePort --port 3000

kubectl get node -o wide

LoadBalancer - service
	does not directly access the node
	access the load balancer
	balances all income traffic accross the pods
	
docker -run -v %cd%:/app:ro -v /app/node_modules -p 3000:3000 -d --name node-app node-app-image


Skaffold.dev

automates many tasks in a kubernetes dev environment, easy to update code in running pod, creation/deletion of objects to a project at once is easy

configuration file in base workspace -- skaffold.yaml

apiVersion: skaffold/v2alpha3
kind: Config
deploy:
  kubectl:
   manifests:
    - ./infra/k8s/*
build:
  local:
   push: false
  artifacts: # rebuild whole image
   - image: stephengrider/auth
     context: auth
  docker:
    dockerfile: Dockerfile 
  sync: 
   manual: #inplace update
    - src: 'src/**/*.js'
      dest: .
	  
skaffold dev

when skaffold is stopped all the objects related to the project will automatically deleted